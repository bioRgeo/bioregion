<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>4.2 Non-hierarchical clustering • bioregion</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<!-- mathjax math --><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script><script>
  window.MathJax = {
    chtml: {
      fontURL: "https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2"
    }
  };
</script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="4.2 Non-hierarchical clustering">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">bioregion</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.2.0.9001</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/bioregion.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-tutorials" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Tutorials</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-tutorials">
<li><a class="dropdown-item" href="../articles/a1_install_binary_files.html">1. Installation of the binary files</a></li>
    <li><a class="dropdown-item" href="../articles/a2_matrix_and_network_formats.html">2. Matrix and network formats</a></li>
    <li><a class="dropdown-item" href="../articles/a3_pairwise_metrics.html">3. Pairwise similarity/dissimilarity metrics</a></li>
    <li><a class="dropdown-item" href="../articles/a4_1_hierarchical_clustering.html">4.1 Hierarchical clustering</a></li>
    <li><a class="dropdown-item" href="../articles/a4_2_non_hierarchical_clustering.html">4.2 Non-hierarchical clustering</a></li>
    <li><a class="dropdown-item" href="../articles/a4_3_network_clustering.html">4.3 Network clustering</a></li>
    <li><a class="dropdown-item" href="../articles/a4_4_microbenchmark.html">4.4 Microbenchmark</a></li>
    <li><a class="dropdown-item" href="../articles/a5_1_visualization.html">5.1 Visualization</a></li>
    <li><a class="dropdown-item" href="../articles/a5_2_compare_bioregionalizations.html">5.2 Compare bioregionalizations</a></li>
    <li><a class="dropdown-item" href="../articles/a5_3_summary_metrics.html">5.3 Summary metrics</a></li>
  </ul>
</li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-applications" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Applications</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-applications">
<li><a class="dropdown-item" href="../articles/citations.html">Citing articles</a></li>
  </ul>
</li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-news" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">News</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-news">
<li><h6 class="dropdown-header" data-toc-skip>Releases</h6></li>
    <li><a class="external-link dropdown-item" href="https://github.com/bioRgeo/bioregion/releases/tag/v1.2.0">Version 1.2.0</a></li>
    <li><a class="external-link dropdown-item" href="https://github.com/bioRgeo/bioregion/releases/tag/v1.1.1">Version 1.1.1</a></li>
    <li><a class="external-link dropdown-item" href="https://github.com/bioRgeo/bioregion/releases/tag/v1.1.0">Version 1.1.0</a></li>
    <li><a class="external-link dropdown-item" href="https://github.com/bioRgeo/bioregion/releases/tag/v1.0.0">Version 1.0.0</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><a class="dropdown-item" href="../news/index.html">Changelog</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/bioRgeo/bioregion/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>4.2 Non-hierarchical clustering</h1>
                        <h4 data-toc-skip class="author">Pierre Denelle,
Boris Leroy and Maxime Lenormand</h4>
            
            <h4 data-toc-skip class="date">2025-09-30</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/bioRgeo/bioregion/blob/master/vignettes/a4_2_non_hierarchical_clustering.Rmd" class="external-link"><code>vignettes/a4_2_non_hierarchical_clustering.Rmd</code></a></small>
      <div class="d-none name"><code>a4_2_non_hierarchical_clustering.Rmd</code></div>
    </div>

    
    
<p>Non-hierarchical clustering consists in creating groups of objects
(called clusters) while maximizing (or minimizing) an evaluating metric.
Contrarily to hierarchical clustering, the partition obtained is not
nested. All functions in <code>bioregion</code> relying on
non-hierarchical clustering start with the prefix <code>nhclu_</code>.
<br> In biogeography, non-hierarchical clustering is usually applied to
identify clusters of sites having similar species compositions. These
clusters are then called bioregions.<br>
Non-hierarchical clustering takes place on the very right-hand size part
of the <code>bioregion</code> conceptual diagram:</p>
<center>
<img align="bottom" width="100%" height="100%" src="../reference/figures/workflow_nonetwork.png">
</center>
<p><br> Although these methods are conceptually simple, their
implementation can be complex and requires important choices on the part
of the user. In the following, we provide a step-by-step guide on how to
do non-hierarchical clustering analyses with <code>bioregion</code>.
Such analysis usually has the following steps.<br><br></p>
<p><em>1. Construct a dissimilarity matrix</em><br>
To initiate the non-hierarchical clustering procedure, we first need to
provide pairwise distances between sites.<br><br><em>2. Clustering</em> Non-hierarchical algorithms rely on a
<strong>user-defined</strong> number of clusters. Once this number is
defined, users can chose among the 3 functions provided in
<code>bioregion</code> to perform non-hierarchical clustering. These
functions are based on centroid-based algorithms (<a href="https://bioRgeo.github.io/bioregion/reference/nhclu_kmeans.html">Kmeans</a>
and <a href="https://bioRgeo.github.io/bioregion/reference/nhclu_pam.html">PAM</a>
) or density-based algorithms (<a href="https://bioRgeo.github.io/bioregion/reference/nhclu_dbscan.html">DBSCAN</a>).<br><br><em>3. Determining the optimal number of clusters</em><br>
The two functions <a href="https://bioRgeo.github.io/bioregion/reference/bioregionalization_metrics.html"><code>bioregionalization_metrics()</code></a>
and <a href="https://bioRgeo.github.io/bioregion/reference/find_optimal_n.html"><code>find_optimal_n()</code></a>
help determining what the optimal number of clusters would be (see <a href="#section4">Section 4</a> of this vignette).<br><br></p>
<div class="section level2">
<h2 id="dissimilarity-indices">1. Dissimilarity indices<a class="anchor" aria-label="anchor" href="#dissimilarity-indices"></a>
</h2>
<p>Pairwise distances between sites can be obtained by running
<code><a href="../reference/dissimilarity.html">dissimilarity()</a></code> on a site-species matrix.</p>
<p>In the example below, we use the fish dataset from the package to
compute distance metrics.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/bioRgeo/bioregion" class="external-link">"bioregion"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"fishmat"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># It is a presence/absence matrix with sites in rows and species in columns</span></span>
<span><span class="va">fishmat</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##          Abramis brama Alburnus alburnus Barbatula barbatula</span></span>
<span><span class="co">## Aa                   1                 1                   1</span></span>
<span><span class="co">## Abula                0                 0                   0</span></span>
<span><span class="co">## Acheloos             0                 0                   0</span></span></code></pre>
<p>We are going to compute the <span class="math inline">\(\beta_{sim}\)</span> diversity metric, which is a
presence-absence dissimilarity index. The formula is as follows:<br><span class="math inline">\(\beta_{sim} = min(b, c) / (a+min(b,
c))\)</span></p>
<p>Where <em>a</em> is the number of species shared by both sites;
<em>b</em> is the number of species occurring only in the first site;
and <em>c</em> is the number of species only occurring only in the
second site.</p>
<p>We typically choose this metric for bioregionalization, because it is
the <strong>turnover</strong> component of the Sorensen index <span class="citation">(Baselga, 2012)</span> (in a nutshell, it tells us how
sites are different because they have distinct species), and because it
has less dependence on species richness than the Jaccard turnover <span class="citation">(Leprieur &amp; Oikonomou, 2014)</span>. <br> The
choice of the distance metric is very important for the outcome of the
clustering procedure, so we recommend that you choose carefully
depending on your research question.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dissim</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dissimilarity.html">dissimilarity</a></span><span class="op">(</span><span class="va">fishmat</span>, metric <span class="op">=</span> <span class="st">"Simpson"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">dissim</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">## Data.frame of dissimilarity between sites</span></span>
<span><span class="co">##  - Total number of sites:  338 </span></span>
<span><span class="co">##  - Total number of species:  195 </span></span>
<span><span class="co">##  - Number of rows:  56953 </span></span>
<span><span class="co">##  - Number of dissimilarity metrics:  1 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## </span></span>
<span><span class="co">##   Site1    Site2   Simpson</span></span>
<span><span class="co">## 2    Aa    Abula 0.3333333</span></span>
<span><span class="co">## 3    Aa Acheloos 1.0000000</span></span>
<span><span class="co">## 4    Aa    Adige 0.7692308</span></span></code></pre>
<p>By default, only the Simpson index is computed, but other options are
available in the <code>metric</code> argument of
<code><a href="../reference/dissimilarity.html">dissimilarity()</a></code>. Furthermore, users can also write down
their own formula to compute any index they wish for in the argument
<code>formula</code>, see <code>?dissimilarity()</code>.</p>
<p>We are now ready to start the non-hierarchical clustering procedure
with the object <code>dissim</code> we have just created. Alternatively,
you can also use other types of objects such as a distance matrix object
(class <code>dist</code>) or a <code>data.frame</code> of your own
crafting (make sure to read the required format carefully as explained
in the help of each function). <br><br></p>
</div>
<div class="section level2">
<h2 id="centroid-based-clustering">2. Centroid-based clustering<a class="anchor" aria-label="anchor" href="#centroid-based-clustering"></a>
</h2>
<p>The core idea of these algorithms is to place points into the cluster
for which a central-point is the closest. This central-point can either
be the centroid of the cluster, i.e. the mean of the x and y coordinates
of all the points belonging to the cluster, or the <a href="#section22">medoid</a>. The medoid is the most centrally located
data point in the cluster, or in other words the least dissimilar point
to all points in the cluster.<br><br> The objective is then to minimize the sum of squared distances
between points and the assigned centroids/medoids.</p>
<div class="section level3">
<h3 id="kmeans">2.1. Kmeans<a class="anchor" aria-label="anchor" href="#kmeans"></a>
</h3>
<p>K-means clustering is perhaps the most famous method of
non-hierarchical clustering. It uses centroids of clusters.<br>
This algorithm usually follows an iterative framework such as:</p>
<ol style="list-style-type: decimal">
<li><p>An initialization step creates <em>k</em> centroids with random
placements.</p></li>
<li><p>For every point, its Euclidean distance with all the centroids is
calculated. Each point is then assigned to its nearest centroid. The
points assigned to the same centroid form a cluster.</p></li>
<li><p>Once clusters are formed, new centroids for each cluster are
calculated by taking the mean of the x and y coordinates of all the
points belonging to the cluster.</p></li>
<li><p>A re-assignment step then calculates new centroids based on the
membership of each cluster. Steps 2 and 3 are repeated until the
solution converges, i.e. when the centroid positions no longer
change.</p></li>
</ol>
<p>Finding an optimal solution to K-means is computationally intensive
and their implementation rely on efficient heuristic algorithms to
quickly converge to a local optimum.</p>
<p><em>Side-note</em><br>
The k-means algorithm can become ‘stuck’ in local optima. Repeating the
clustering algorithm and adding noise to the data can help evaluate the
robustness of the solution.</p>
<p><br> The function to compute K-means clustering in
<code>bioregion</code> is <code><a href="../reference/nhclu_kmeans.html">nhclu_kmeans()</a></code>. We here
illustrate how the functions works with an example applied on the
dissimilarity matrix calculated above.<br>
We chose 3 clusters.<br><br> All the above steps come with arguments that can be tweaked.
Specifically, <code>iter_max</code> determines the maximum number of
iterations allowed (i.e. how many times the steps described above are
run) and <code>nstart</code> specifies how many random sets of
<code>n_clust</code> should be selected as starting points. <br> Several
heuristic algorithms can also be used along with the K-means method and
this can be parameterized using the <code>algorithm</code> argument. By
default, the algorithm of Hartigan-Wong (<span class="citation">Hartigan
&amp; Wong (1979)</span>) is used.<br><br> Let’s start by setting both <code>iter_max</code> and
<code>nstart</code> to 1.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ex_kmeans</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhclu_kmeans.html">nhclu_kmeans</a></span><span class="op">(</span><span class="va">dissim</span>, index <span class="op">=</span> <span class="st">"Simpson"</span>, n_clust <span class="op">=</span> <span class="fl">3</span>, iter_max <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                          nstart <span class="op">=</span> <span class="fl">1</span>, algorithm <span class="op">=</span> <span class="st">"Hartigan-Wong"</span><span class="op">)</span></span></code></pre></div>
<p>When asking for one iteration only, the function displays a message
saying that the algorithm did not converge.<br>
We therefore need to increase the value of <code>iter_max</code>.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ex_kmeans</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhclu_kmeans.html">nhclu_kmeans</a></span><span class="op">(</span><span class="va">dissim</span>, index <span class="op">=</span> <span class="st">"Simpson"</span>, n_clust <span class="op">=</span> <span class="fl">3</span>, iter_max <span class="op">=</span> <span class="fl">3</span>,</span>
<span>                          nstart <span class="op">=</span> <span class="fl">1</span>, algorithm <span class="op">=</span> <span class="st">"Hartigan-Wong"</span><span class="op">)</span></span></code></pre></div>
<p>Like for all other functions of the <code>bioregion</code> package,
the <code>class</code> of the object is specific for the package (here
<code>bioregion.clusters</code>) and it contains several parts. The
clusters assigned to each site are accessible in the
<code>$clusters</code> part of the output:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ex_kmeans</span><span class="op">$</span><span class="va">clusters</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##                ID K_3</span></span>
<span><span class="co">## Aa             Aa   3</span></span>
<span><span class="co">## Abula       Abula   1</span></span>
<span><span class="co">## Acheloos Acheloos   2</span></span></code></pre>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">ex_kmeans</span><span class="op">$</span><span class="va">clusters</span><span class="op">$</span><span class="va">K_3</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">##   1   2   3 </span></span>
<span><span class="co">## 142  93 103</span></span></code></pre>
<p>Here, we see that 142 sites are assigned to cluster 1, 93 to cluster
2 and 103 to cluster 3.<br><br> This assignment can change depending on the two other main
arguments of the functions, <code>iter_max</code> and
<code>nstart</code>.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ex_kmeans2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhclu_kmeans.html">nhclu_kmeans</a></span><span class="op">(</span><span class="va">dissim</span>, index <span class="op">=</span> <span class="st">"Simpson"</span>, n_clust <span class="op">=</span> <span class="fl">3</span>,</span>
<span>                           iter_max <span class="op">=</span> <span class="fl">100</span>, nstart <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                           algorithm <span class="op">=</span> <span class="st">"Hartigan-Wong"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">ex_kmeans3</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhclu_kmeans.html">nhclu_kmeans</a></span><span class="op">(</span><span class="va">dissim</span>, index <span class="op">=</span> <span class="st">"Simpson"</span>, n_clust <span class="op">=</span> <span class="fl">3</span>,</span>
<span>                           iter_max <span class="op">=</span> <span class="fl">3</span>, nstart <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                           algorithm <span class="op">=</span> <span class="st">"Hartigan-Wong"</span><span class="op">)</span></span></code></pre></div>
<p>As shown below, the distribution of sites among the three clusters
appears quite homogeneous with our three examples but some discrepancies
emerge.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">ex_kmeans</span><span class="op">$</span><span class="va">clusters</span><span class="op">$</span><span class="va">K_3</span>, <span class="va">ex_kmeans2</span><span class="op">$</span><span class="va">clusters</span><span class="op">$</span><span class="va">K_3</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    </span></span>
<span><span class="co">##       1   2   3</span></span>
<span><span class="co">##   1   1  12 129</span></span>
<span><span class="co">##   2  77  16   0</span></span>
<span><span class="co">##   3   0   9  94</span></span></code></pre>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">ex_kmeans</span><span class="op">$</span><span class="va">clusters</span><span class="op">$</span><span class="va">K_3</span>, <span class="va">ex_kmeans3</span><span class="op">$</span><span class="va">clusters</span><span class="op">$</span><span class="va">K_3</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    </span></span>
<span><span class="co">##       1   2   3</span></span>
<span><span class="co">##   1 111  29   2</span></span>
<span><span class="co">##   2   0   0  93</span></span>
<span><span class="co">##   3   0 102   1</span></span></code></pre>
<p><br> Overall, increasing <code>iter_max</code> and
<code>nstart</code> increases the chances of convergence of the
algorithm but also increases the computation time.<br><br></p>
</div>
<div class="section level3">
<h3 id="section22">2.2. K-medoids<a class="anchor" aria-label="anchor" href="#section22"></a>
</h3>
<p>Instead of using the mean of the cluster, the medoid can also be used
to partition the data points.<br><br> In comparison with the centroid used for K-means, the medoid is
less sensitive to outliers in the data. These partitions can also use
other types of distances and do not have to rely on the Euclidean
distance only.<br><br> Several heuristics exist to solve the K-medoids problem, the most
famous ones being the Partition Around Medoids (PAM), and its extensions
CLARA and CLARANS.</p>
<div class="section level4">
<h4 id="partitioning-around-medoids-pam">2.2.1. Partitioning Around Medoids (PAM)<a class="anchor" aria-label="anchor" href="#partitioning-around-medoids-pam"></a>
</h4>
<p>PAM is a fast heuristic to find a solution to the k-medoids problem.
With <em>k</em> clusters, it decomposes following these steps: <br> 1.
Randomly pick <em>k</em> points as initial medoids</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Assign each point to the nearest medoid <em>x</em></p></li>
<li><p>Calculate the objective function (the sum of dissimilarities of
all points to their nearest medoids)</p></li>
<li><p>Randomly select a point <em>y</em></p></li>
<li><p>Swap <em>x</em> by <em>y</em> if the swap reduces the objective
function</p></li>
<li><p>Repeat 3-6 until no change<br><br></p></li>
</ol>
<p>In the <code><a href="../reference/nhclu_pam.html">nhclu_pam()</a></code> function, there are several arguments
to tweak. The number of clusters <code>n_clust</code> has to be defined
as well as the number of starting positions for the medoids
<code>nstart</code>.<br>
Several variants of the PAM algorithm are available and can be changed
with the argument <code>variant</code> (see <code><a href="https://rdrr.io/pkg/cluster/man/pam.html" class="external-link">cluster::pam()</a></code>
for more details).</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ex_pam</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhclu_pam.html">nhclu_pam</a></span><span class="op">(</span><span class="va">dissim</span>, index <span class="op">=</span> <span class="st">"Simpson"</span>, n_clust <span class="op">=</span> <span class="fl">2</span><span class="op">:</span><span class="fl">25</span>, nstart <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                    variant <span class="op">=</span> <span class="st">"faster"</span>, cluster_only <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">ex_pam</span><span class="op">$</span><span class="va">clusters</span><span class="op">$</span><span class="va">K_2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">##   1   2 </span></span>
<span><span class="co">## 258  80</span></span></code></pre>
<p>With 2 clusters, we see that 258 sites are assigned to cluster 1 and
80 to cluster 2. <br></p>
</div>
<div class="section level4">
<h4 id="clustering-large-applications-clara">2.2.2. Clustering Large Applications (CLARA)<a class="anchor" aria-label="anchor" href="#clustering-large-applications-clara"></a>
</h4>
<p>CLARA (Clustering Large Applications, (Kaufman and Rousseeuw 1990))
is an extension of the k-medoids (PAM) methods to deal with data
containing a large number of objects (more than several thousand
observations) in order to reduce the computational time and the RAM
storage problem. This is achieved by using the sampling approach.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ex_clara</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhclu_clara.html">nhclu_clara</a></span><span class="op">(</span><span class="va">dissim</span>, index <span class="op">=</span> <span class="st">"Simpson"</span>,</span>
<span>                        n_clust <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                        maxiter <span class="op">=</span> <span class="fl">0L</span>, initializer <span class="op">=</span> <span class="st">"LAB"</span>, fasttol <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                        numsamples <span class="op">=</span> <span class="fl">5L</span>, sampling <span class="op">=</span> <span class="fl">0.25</span>, independent <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                        seed <span class="op">=</span> <span class="fl">123456789L</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">ex_clara</span><span class="op">$</span><span class="va">clusters</span><span class="op">$</span><span class="va">K_5</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">##   1   2   3   4   5 </span></span>
<span><span class="co">## 241  21  16  50  10</span></span></code></pre>
</div>
<div class="section level4">
<h4 id="clustering-large-applications-based-on-randomized-search-clarans">2.2.3. Clustering Large Applications based on RANdomized Search
(CLARANS)<a class="anchor" aria-label="anchor" href="#clustering-large-applications-based-on-randomized-search-clarans"></a>
</h4>
<p>CLARANS (Clustering Large Applications based on RANdomized Search,
(Ng and Han 2002)) is an extension of the k-medoids (PAM) methods
combined with the CLARA algorithm.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ex_clarans</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhclu_clarans.html">nhclu_clarans</a></span><span class="op">(</span><span class="va">dissim</span>, index <span class="op">=</span> <span class="st">"Simpson"</span>,</span>
<span>                        n_clust <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                        numlocal <span class="op">=</span> <span class="fl">2L</span>, maxneighbor <span class="op">=</span> <span class="fl">0.025</span>,</span>
<span>                        seed <span class="op">=</span> <span class="fl">123456789L</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">ex_clara</span><span class="op">$</span><span class="va">clusters</span><span class="op">$</span><span class="va">K_5</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">##   1   2   3   4   5 </span></span>
<span><span class="co">## 241  21  16  50  10</span></span></code></pre>
</div>
</div>
</div>
<div class="section level2">
<h2 id="density-based-clustering">3. Density-based clustering<a class="anchor" aria-label="anchor" href="#density-based-clustering"></a>
</h2>
<p>Density-based clustering is another type of non-hierarchical
clustering. It connects areas of high density into clusters. This allows
for arbitrary-shaped distributions as long as dense areas can be
connected. These algorithms can however have difficulty with data of
varying densities and high dimensions.</p>
<div class="section level3">
<h3 id="dbscan">3.1. DBSCAN<a class="anchor" aria-label="anchor" href="#dbscan"></a>
</h3>
<p>Density-based Spatial Clustering of Applications with Noise (DBSCAN)
(<span class="citation">Hahsler <em>et al.</em> (2019)</span>) is the
most famous density-based clustering approach. <br> It operates by
locating points in the dataset that are surrounded by a significant
number of other points. These points are regarded to be part of a dense
zone, and the algorithm will next attempt to extend this region to
encompass all of the cluster’s points.</p>
<p><br> DBSCAN uses the two following parameters:</p>
<p>Epsilon (<code>eps</code>): the maximum distance between two points
to be considered as neighboring points (belonging to the same
cluster).</p>
<p>Minimum Points (<code>minPts</code>): The minimum number of
neighboring points that a given point needs to be considered a core data
point. This includes the point itself. For example, if minimum number of
points is set to 4, then a given point needs to have 3 or more
neighboring data points to be considered a core data point.</p>
<p>If minimum number of points meet the epsilon distance requirement
then they are considered as a cluster. <br></p>
<p>Having set these two parameters, the algorithm works like this:</p>
<ol style="list-style-type: decimal">
<li><p>Decide the value of <code>eps</code> and
<code>minPts</code>.</p></li>
<li><p>For each point: Calculate its distance from all other points. If
the distance is less than or equal to <code>eps</code> then mark that
point as a neighbor of x. If the point gets a neighboring count greater
than or equal to <code>minPts</code>, then mark it as a core point or
visited.</p></li>
<li><p>For each core point, if it not already assigned to a cluster than
create a new cluster. Recursively find all its neighboring points and
assign them the same cluster as the core point.</p></li>
<li><p>Continue these steps until all the unvisited points are
covered.</p></li>
</ol>
<p><br> This algorithm can be called with the function
<code><a href="../reference/nhclu_dbscan.html">nhclu_dbscan()</a></code>. If the user does not define the two
arguments presented above, <code>minPts</code> and <code>eps</code>,
then the function will provide a knee curve helping the search of an
optimal <code>eps</code> value. <br></p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ex_dbscan</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhclu_dbscan.html">nhclu_dbscan</a></span><span class="op">(</span><span class="va">dissim</span>, index <span class="op">=</span> <span class="st">"Simpson"</span>, minPts <span class="op">=</span> <span class="cn">NULL</span>, eps <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>                          plot <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Trying to find a knee in the curve to search for an optimal eps value...</span></span>
<span><span class="co">##        NOTE: this automatic identification of the knee may not work properly</span></span>
<span><span class="co">##        if the curve has knees and elbows. Please adjust eps manually by</span></span>
<span><span class="co">##        inspecting the curve, identifying a knee as follows:</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##                            /</span></span>
<span><span class="co">##                  curve    /</span></span>
<span><span class="co">##               ___________/  &lt;- knee</span></span>
<span><span class="co">##   elbow -&gt;   /</span></span>
<span><span class="co">##             /</span></span>
<span><span class="co">##            /</span></span></code></pre>
<p><img src="a4_2_non_hierarchical_clustering_files/figure-html/unnamed-chunk-11-1.png" width="576"></p>
<p>Here, we see that we can set <code>eps</code> to 1.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ex_dbscan2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhclu_dbscan.html">nhclu_dbscan</a></span><span class="op">(</span><span class="va">dissim</span>, index <span class="op">=</span> <span class="st">"Simpson"</span>, minPts <span class="op">=</span> <span class="cn">NULL</span>, eps <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                           plot <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p>With this set of parameters, we only get one cluster.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">ex_dbscan2</span><span class="op">$</span><span class="va">clusters</span><span class="op">$</span><span class="va">K_1</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">##   1 </span></span>
<span><span class="co">## 338</span></span></code></pre>
<p>If we decrease the <code>eps</code> value and increase
<code>minPts</code>, we can get more clusters.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ex_dbscan3</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhclu_dbscan.html">nhclu_dbscan</a></span><span class="op">(</span><span class="va">dissim</span>, index <span class="op">=</span> <span class="st">"Simpson"</span>, minPts <span class="op">=</span> <span class="fl">4</span>, eps <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>                           plot <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">ex_dbscan3</span><span class="op">$</span><span class="va">clusters</span><span class="op">$</span><span class="va">K_2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## &lt; table of extent 0 &gt;</span></span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="section4">4. Affinity propagation<a class="anchor" aria-label="anchor" href="#section4"></a>
</h2>
<p>This algorithm is based on the paper of <span class="citation">Frey
&amp; Dueck (2007)</span> and relies on the R package <a href="https://cran.r-project.org/package=apcluster" class="external-link">apcluster</a></p>
<p>Unlike the previous algorithms in this vignette, this algorithm and
its associated function use a similarity matrix.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Similarity matrix</span></span>
<span><span class="va">sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dissimilarity_to_similarity.html">dissimilarity_to_similarity</a></span><span class="op">(</span><span class="va">dissim</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Algorithm</span></span>
<span><span class="va">clust1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhclu_affprop.html">nhclu_affprop</a></span><span class="op">(</span><span class="va">sim</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="section5">5. Optimal number of clusters<a class="anchor" aria-label="anchor" href="#section5"></a>
</h2>
<p>Previous methods did not help in determining the optimal number of
bioregions structuring the site-species matrix.</p>
<p>For this purpose, we can combine both functions
<code><a href="../reference/bioregionalization_metrics.html">bioregionalization_metrics()</a></code> and
<code><a href="../reference/find_optimal_n.html">find_optimal_n()</a></code>.</p>
<p><code><a href="../reference/bioregionalization_metrics.html">bioregionalization_metrics()</a></code> calcultes several metrics
based on the previous clustering attempts.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/bioregionalization_metrics.html">bioregionalization_metrics</a></span><span class="op">(</span><span class="va">ex_pam</span>, dissimilarity <span class="op">=</span> <span class="va">dissim</span>,</span>
<span>                           eval_metric <span class="op">=</span> <span class="st">"pc_distance"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Partition metrics:</span></span>
<span><span class="co">##  - 24  partition(s) evaluated</span></span>
<span><span class="co">##  - Range of clusters explored: from  2  to  25 </span></span>
<span><span class="co">##  - Requested metric(s):  pc_distance </span></span>
<span><span class="co">##  - Metric summary:</span></span>
<span><span class="co">##      pc_distance</span></span>
<span><span class="co">## Min    0.5464742</span></span>
<span><span class="co">## Mean   0.8022971</span></span>
<span><span class="co">## Max    0.8949633</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Access the data.frame of metrics with your_object$evaluation_df</span></span></code></pre>
<p>*Note For the two metrics <code>tot_endemism</code> and
<code>avg_endemism</code>, you also need to provide the site-species
matrix.</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">a</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bioregionalization_metrics.html">bioregionalization_metrics</a></span><span class="op">(</span><span class="va">ex_pam</span>, dissimilarity <span class="op">=</span> <span class="va">dissim</span>, net <span class="op">=</span> <span class="va">fishdf</span>,</span>
<span>                                species_col <span class="op">=</span> <span class="st">"Species"</span>, site_col <span class="op">=</span> <span class="st">"Site"</span>,</span>
<span>                                eval_metric <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"tot_endemism"</span>, <span class="st">"avg_endemism"</span>,</span>
<span>                                                <span class="st">"pc_distance"</span>, <span class="st">"anosim"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Once the <code><a href="../reference/bioregionalization_metrics.html">bioregionalization_metrics()</a></code> function has
calculated the partitioning metrics, we can call
<code><a href="../reference/find_optimal_n.html">find_optimal_n()</a></code> to get the optimal number of clusters.
<br></p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/find_optimal_n.html">find_optimal_n</a></span><span class="op">(</span><span class="va">a</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Number of bioregionalizations: 24</span></span></code></pre>
<pre><code><span><span class="co">## Searching for potential optimal number(s) of clusters based on the elbow method</span></span></code></pre>
<pre><code><span><span class="co">##    * elbow found at:</span></span></code></pre>
<pre><code><span><span class="co">## tot_endemism 4</span></span>
<span><span class="co">## avg_endemism 4</span></span>
<span><span class="co">## pc_distance 7</span></span>
<span><span class="co">## anosim 2</span></span></code></pre>
<pre><code><span><span class="co">## Plotting results...</span></span></code></pre>
<p><img src="a4_2_non_hierarchical_clustering_files/figure-html/unnamed-chunk-18-1.png" width="576"></p>
<pre><code><span><span class="co">## Search for an optimal number of clusters:</span></span>
<span><span class="co">##  - 24  partition(s) evaluated</span></span>
<span><span class="co">##  - Range of clusters explored: from  2  to  25 </span></span>
<span><span class="co">##  - Evaluated metric(s):  tot_endemism avg_endemism pc_distance anosim </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Potential optimal partition(s):</span></span>
<span><span class="co">##  - Criterion chosen to optimise the number of clusters:  elbow </span></span>
<span><span class="co">##  - Optimal partition(s) of clusters for each metric:</span></span>
<span><span class="co">## tot_endemism - 4</span></span>
<span><span class="co">## avg_endemism - 4</span></span>
<span><span class="co">## pc_distance - 7</span></span>
<span><span class="co">## anosim - 2</span></span></code></pre>
<p>Based on the metric selected, the optimal number of clusters can
vary.</p>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">6. References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="1">
<div id="ref-Baselga2012" class="csl-entry">
Baselga A (2012) The relationship between species replacement,
dissimilarity derived from nestedness, and nestedness. <em>Global
Ecology and Biogeography</em> 21, 1223–1232.
</div>
<div id="ref-Frey2007" class="csl-entry">
Frey B &amp; Dueck D (2007) Clustering by passing messages between data
points. <em>Science</em> 315, 972–976.
</div>
<div id="ref-Hahsler2019" class="csl-entry">
Hahsler M, Piekenbrock M &amp; Doran D (2019) Dbscan: Fast density-based
clustering with r. <em>Journal of Statistical Software</em> 91, 1–30.
</div>
<div id="ref-Hartigan1979" class="csl-entry">
Hartigan JA &amp; Wong MA (1979) Algorithm <span>AS</span> 136:
<span>A</span> k-means clustering algorithm. <em>Journal of the royal
statistical society. series c (applied statistics)</em> 28, 100–108.
</div>
<div id="ref-Leprieur2014" class="csl-entry">
Leprieur F &amp; Oikonomou A (2014) <span class="nocase">The need for
richness-independent measures of turnover when delineating
biogeographical regions</span>. <em>Journal of Biogeography</em> 41,
417–420.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Maxime Lenormand, Boris Leroy, Pierre Denelle.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
